{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7e9fad2-ac87-4dd6-aab1-468524a4ff54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# CDC - DLT Bronze Demo\n",
    "\n",
    "**Summary:**\n",
    "- Purpose:\n",
    "  - Ingest incremental CDC files from s3 into raw bronze table\n",
    "- Tools: \n",
    "  - autoloader\n",
    "- Input: \n",
    "  - CDC parquet files in s3 bucket\n",
    "- Output: \n",
    "  - my_catalog.my_schema.cdc_bronze_orders\n",
    "    - data types are all string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccfc9e6f-7cc6-409c-b103-b08694bbe954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this notebook, we will demo how to build a **DLT**(Delta-Live-Tables), using ***Autoloader***. \n",
    "We will cover\n",
    "- CDC to Bronze raw\n",
    "  - Support schema evolution\n",
    "\n",
    "We also comment out the code for defining schema explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "672f0242-3d25-44fa-b8bd-6dc267a8ecbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CDC to Bronze raw\n",
    "- CDC parquet files get dumpled into s3\n",
    "- Autoloader detects new files and load it into cdc_bronze_orders as appending behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fea6d1d5-15f7-4654-9266-a736046a942c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define DLT table\n",
    "@dlt.table(\n",
    "    name=\"cdc_bronze_orders\",\n",
    "    comment=\"Bronze table to capture raw CDC data for orders.\"\n",
    ")\n",
    "def bronze_cdc_data():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")                         # autoloader to ingest data\n",
    "        .option(\"cloudFiles.format\", \"parquet\")                       # specify underlying file format\n",
    "        .load(\"/Volumes/neo_zhou/client_demo_schema_evolution/cdc_volume_managed\")                # repalce with path to your cdc volume, recommend configuring a managed volume for it\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42b74478-09ae-4a94-b161-62aec904f71d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Check SQL Editor panel for generated results\n",
    "\n",
    "After this step, Catalog will have a table *neo_zhou.client_demo.cdc_bronze_orders*.    \n",
    "\n",
    "Run the following code in SQL panel to validate:  \n",
    "*SELECT \\* FROM neo_zhou.client_demo_schema_evolution.cdc_bronze_orders*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a05638f-007c-43e7-bfd0-acbe29c2c716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix: define schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60316cd6-27d5-4e9f-bddc-d382aeea05c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import dlt\n",
    "# from pyspark.sql.functions import *\n",
    "\n",
    "# # Define the schema for CDC data to structure the data correctly\n",
    "# cdc_schema = \"\"\"schema STRING, \n",
    "#                 table STRING, \n",
    "#                 operation STRING, \n",
    "#                 timestamp STRING, \n",
    "                \n",
    "#                 data STRUCT<order_id: INT, \n",
    "#                             customer_id: INT, \n",
    "#                             order_date: STRING, \n",
    "#                             amount: DOUBLE, \n",
    "#                             status: STRING>,\n",
    "\n",
    "#                 old_data STRUCT<amount: DOUBLE, \n",
    "#                                 status: STRING>\n",
    "#               \"\"\"\n",
    "\n",
    "# @dlt.table(\n",
    "#     name=\"cdc_bronze_orders\",\n",
    "#     comment=\"Bronze table to capture raw CDC data for orders.\"\n",
    "# )\n",
    "# def bronze_cdc_data():\n",
    "#     return (\n",
    "#         spark.readStream.format(\"cloudFiles\")           # autoloader way to ingest data\n",
    "#         .option(\"cloudFiles.format\", \"json\")            # specify underlying file format\n",
    "#         .schema(cdc_schema)                             # using the defined schema\n",
    "#         .load(\"s3://neo-client-demo-tokyo/cdc_volume\")  # Replace with the path to your volume\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "CDC_DLT_bronze_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
